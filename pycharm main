import logging

import azure.functions as func
import openai
from tqdm.auto import tqdm
import pinecone
import datetime
import json
from time import sleep


#def main(req: func.HttpRequest) -> func.HttpResponse:
    # logging.info('Python HTTP trigger function processed a request.')
    # openai.api_key = "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"
    # data = req.get_json()
    # query = data['myQuery']
    # pdfData = data['pdfContent']
    # # logging.info('My PDF data is'+req.get_json())
    # myResponse, id = semanticSearchQA(query, pdfData)
    # # return func.HttpResponse(f"PDF data is : {data['pdfContent']}.")
    # return func.HttpResponse(f"Answer is : {myResponse}. Id is : {id}. and my content is {pdfData}")

def process_request(pdf_content, inp_query):
    logging.info('Python HTTP trigger function processed a request.')
    openai.api_key = "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"
    query = inp_query
    pdfData = pdf_content
    # logging.info('My PDF data is'+req.get_json())
    myResponse, id, responseText = semanticSearchQA(query, pdfData)
    # return func.HttpResponse(f"PDF data is : {data['pdfContent']}.")
    print(f"Answer is : {myResponse}. Id is : {id}. and its text is: {responseText}")


def complete(prompt):
    # query text-davinci-003
    res = openai.Completion.create(
        engine='text-davinci-003',
        prompt=prompt,
        temperature=0,
        max_tokens=400,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )

    # myResponse = res['choices'][0]['text'].strip()
    # id = res['choices'][0]['id'].strip()
    return res['choices'][0]['text'].strip()


def retrieve(query, embed_model, index):
    limit = 3750
    res = openai.Embedding.create(
        input=[query],
        engine=embed_model
    )

    # retrieve from Pinecone
    xq = res['data'][0]['embedding']

    # get relevant contexts
    res = index.query(xq, top_k=3, include_metadata=True)
    print(f"response pre: {res['matches'][0]['id']}")
    contexts = [
        x['metadata']['text'] for x in res['matches']
    ]

    responseId = res['matches'][0]['id']
    responseText = res['matches'][0]['metadata']['text']
    #
    # esponseId = res['matches'][0]['text']

    # print(myIds)

    # build our prompt with the retrieved contexts included
    prompt_start = (
            "Reply to the question based on the text below, and if the answer is not clear based on the text, say 'Sorry I couldnâ€™t find answer to your question, please consult with your doctor'.\n\n" +
            "Context:\n"
    )
    prompt_end = (
        f"\n\nQuestion: {query}\nAnswer:"
    )
    # append contexts until hitting limit
    contextIds = []
    for i in range(1, len(contexts)):
        if len("\n\n---\n\n".join(contexts[:i])) >= limit:
            prompt = (
                    prompt_start +
                    "\n\n---\n\n".join(contexts[:i - 1]) +
                    prompt_end
            )
            # contextIds.append(myIds[i])
            break
        elif i == len(contexts) - 1:
            prompt = (
                    prompt_start +
                    "\n\n---\n\n".join(contexts) +
                    prompt_end
            )
            # contextIds.append(myIds[i])
    # print(f"responseId: {responseId}, prompt : {prompt}")
    return prompt, responseId, responseText


def semanticSearchQA(query, pdfData):
    embed_model = "text-embedding-ada-002"

    logging.info('My PDF data is' + pdfData)

    myPdfContent = pdfData.split(".")
    data = []
    i = 0
    for x in myPdfContent:
        x = x.replace("\n","")
        myPdfContent[i] = x
        i = i + 1





    print(f"data: {data}")
    print(f'After -> myPdfContent:: {myPdfContent}')

    # myPdfContent = pdfData.split(".")
    # i = 0
    # for x in myPdfContent:
    #     x = x.replace("\n","")
    #     myPdfContent[i] = x
    #     i = i + 1

    res = openai.Embedding.create(
        input=[
            "Hi",
            "Hello"
        ], engine=embed_model
    )

    # data = []
    # data.append({
    #     'text': myPdfContent[0],
    #     'id': "020520230624"
    # })
    # data.append({
    #     'text': myPdfContent[1],
    #     'id': "020520230625"
    # })
    id = 20520230624
    t = 0
    for text in myPdfContent:
        id = id + 1
        if t<6:
            data.append({
                    'text': text,
                    'id': str(id)
                })
            t=t+1


    new_data = []

    window = 20  # number of sentences to combine

    for i in tqdm(range(0, len(data))):
        # i_end = min(len(data)-1, i+window)
        text = ''.join(data[i]['text'])
        # create the new merged dataset
        new_data.append({
            'text': text,
            'id': data[i]['id']
        })

    index_name = 'openai-jd-paracetamol'

    # initialize connection to pinecone (get API key at app.pinecone.io)
    pinecone.init(
        api_key="794cb85f-7864-4d0c-a544-1c50a2eb91b7",
        environment="us-east1-gcp"  # may be different, check at app.pinecone.io
    )

    print(pinecone.list_indexes())

    # check if index already exists (it shouldn't if this is first time)
    if index_name not in pinecone.list_indexes():
        # if does not exist, create index
        pinecone.create_index(
            index_name,
            dimension=len(res['data'][0]['embedding']),
            metric='cosine',
            metadata_config={'indexed': ['id']}
        )
    # connect to index
    index = pinecone.Index(index_name)
    # view index stats
    index.describe_index_stats()

    batch_size = 100  # how many embeddings we create and insert at once

    for i in tqdm(range(0, len(new_data), batch_size)):
        # find end of batch
        i_end = min(len(new_data), i + batch_size)
        meta_batch = new_data[i:i_end]
        # get ids
        ids_batch = [x['id'] for x in meta_batch]
        # get texts to encode
        texts = [x['text'] for x in meta_batch]
        # create embeddings (try-except added to avoid RateLimitError)
        try:
            res = openai.Embedding.create(input=texts, engine=embed_model)
        except:
            done = False
            while not done:
                sleep(5)
                try:
                    res = openai.Embedding.create(input=texts, engine=embed_model)
                    done = True
                except:
                    pass
        embeds = [record['embedding'] for record in res['data']]
        # cleanup metadata
        meta_batch = [{
            'text': x['text'],
            'id': x['id']
        } for x in meta_batch]
        to_upsert = list(zip(ids_batch, embeds, meta_batch))
        # upsert to Pinecone
        index.upsert(vectors=to_upsert)

    query_with_contexts, responseId, responseText = retrieve(query, embed_model, index)
    return complete(query_with_contexts), responseId, responseText
